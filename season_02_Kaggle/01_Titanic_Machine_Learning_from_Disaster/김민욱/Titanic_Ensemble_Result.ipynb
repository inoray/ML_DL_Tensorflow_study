{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble을 이용한 타이타닉 생존자 예측 결과"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* pasdas를 사용하여 csv 파일을 컨트롤 해본다.\n",
    "* ensemble을 구현해본다.\n",
    "* 타이타닉 문제를 풀어본다.\n",
    "* 기타  프로젝트 중 직면한 문제를 해결해본다.\n",
    "    - 학습 중, Error Rate가 Nan이 되는 문제 해결\n",
    "* 그래프를 그려본다......가 추가되었다.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 코드 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* pasdas를 import 하였습니다.\n",
    "* anaconda에 pandas를 추가하는 과정을 수행했습니다....--;;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"./data/train.csv\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    0\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = train['Survived']\n",
    "train_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                               Name  \\\n",
       "0            1       3                            Braund, Mr. Owen Harris   \n",
       "1            2       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2            3       3                             Heikkinen, Miss. Laina   \n",
       "3            4       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4            5       3                           Allen, Mr. William Henry   \n",
       "\n",
       "      Sex   Age  SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "0    male  22.0      1      0         A/5 21171   7.2500   NaN        S  \n",
       "1  female  38.0      1      0          PC 17599  71.2833   C85        C  \n",
       "2  female  26.0      0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3  female  35.0      1      0            113803  53.1000  C123        S  \n",
       "4    male  35.0      0      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = train.drop(labels='Survived', axis=1)\n",
    "train_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x  = pd.read_csv(\"./data/test.csv\")\n",
    "test_x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TINANIC Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TITANIC:\n",
    "        \n",
    "    def __init__(self):\n",
    "        print(\"Created Titanic Object!\")\n",
    "    \n",
    "    ############ Loading Data ############\n",
    "    \n",
    "    def load_train_data(self, cvs_file_path):\n",
    "        \n",
    "        ## pandas csv load\n",
    "        self.train_data = pd.read_csv(cvs_file_path)\n",
    "                \n",
    "        self.train_y_data = self.train_data['Survived']\n",
    "        self.train_y = self.train_y_data.reshape(-1,1)\n",
    "        \n",
    "        # Logistic Regression 이므로 onehot은 필요없다.\n",
    "        # self.train_y_onehot = pd.get_dummies(self.train_y)\n",
    "        \n",
    "        self.train_x = self.train_data.drop(labels='Survived', axis=1)\n",
    "        \n",
    "    def load_test_data(self, cvs_file_path):\n",
    "        \n",
    "        ## pandas cvs load\n",
    "        self.test_data  = pd.read_csv(cvs_file_path)\n",
    "    \n",
    "    ############ Normalize Data ############\n",
    "    \n",
    "    # list의 최대값, 최소값을 받아서 0~1 사이의 값으로 바꾼다.\n",
    "    def normalize_data(self, data_list, data):\n",
    "        \n",
    "        '''\n",
    "        # 정규분포로 바꾼다.\n",
    "        data_avr = np.mean(data_list)\n",
    "        data_std = np.std(data_list)\n",
    "        \n",
    "        data_normal = (data_list-data_avr)/data_std\n",
    "        '''\n",
    "        \n",
    "        data_normal = data_list\n",
    "        max_value = np.max(data_normal)\n",
    "        min_value = np.min(data_normal)\n",
    "        data_normal = (data_normal-min_value)/(max_value-min_value)\n",
    "        \n",
    "        if data.size == 2:\n",
    "            data = data_normal\n",
    "        else:\n",
    "            data = np.vstack( (data, data_normal) )\n",
    "            \n",
    "        return data\n",
    "    \n",
    "    ## 데이터가 영문 단어일 경우 처리!\n",
    "    def normalize_char_data(self, data_list, data):\n",
    "        \n",
    "        # print(data_list.size)\n",
    "        temp_data = np.zeros([data_list.size], dtype=np.float32)\n",
    "        # print(temp_data.shape)\n",
    "        for i in range(data_list.size):\n",
    "            # SEX\n",
    "            if data_list[i]=='male':\n",
    "                temp_data[i] = 0\n",
    "            elif data_list[i]=='female':\n",
    "                temp_data[i] = 1\n",
    "            # Embarked\n",
    "            elif data_list[i]=='S':\n",
    "                temp_data[i] = 0\n",
    "            elif data_list[i]=='C':\n",
    "                temp_data[i] = 1\n",
    "            elif data_list[i]=='Q':\n",
    "                temp_data[i] = 2\n",
    "            # ETC\n",
    "            else:\n",
    "                temp_data[i] = 0\n",
    "        \n",
    "        data = self.normalize_data(temp_data, data)\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    def normalize_ticket_data(self, data_list, data):\n",
    "        \n",
    "        temp_data = []\n",
    "        \n",
    "        # 일단 ticket data에서 맨 뒷자리 공백까지의 숫자를 가져온다.\n",
    "        for i in range(data_list.size):\n",
    "            first_index = data_list[i].rfind(\" \")+1\n",
    "            temp_data.append(data_list[i][first_index:])\n",
    "        \n",
    "        # \"LINE\" 처리\n",
    "        length_list = np.zeros([len(temp_data)], dtype=np.int32)\n",
    "        for i in range(len(temp_data)):\n",
    "            if temp_data[i] == \"LINE\":\n",
    "                temp_data[i] = \"00\"\n",
    "        \n",
    "        # 티켓 번호의 자리수 분석\n",
    "        length_list = np.zeros([len(temp_data)], dtype=np.int32)\n",
    "        for i in range(len(temp_data)):\n",
    "            length_list[i] = len(temp_data[i])\n",
    "        \n",
    "        data = self.normalize_data(length_list, data)\n",
    "        \n",
    "        # 티켓 번호의 맨 앞자리수 분석\n",
    "        first_char_list = np.zeros([len(temp_data)], dtype=np.int32)\n",
    "        for i in range(len(temp_data)):\n",
    "            first_char_list[i] = (int)(temp_data[i][0])\n",
    "        \n",
    "        data = self.normalize_data(length_list, data)\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    def normalize_cabin_data(self, data_list, data):\n",
    "        \n",
    "        temp_data = []\n",
    "        # cabin의 앞자리 문자를 가져온다.\n",
    "        for i in range(data_list.size):\n",
    "            temp_data.append(data_list[i][0])\n",
    "        \n",
    "        cabin_list = np.zeros([len(temp_data)], dtype=np.int32)\n",
    "        for i in range(len(temp_data)):\n",
    "            \n",
    "            if temp_data[i]=='A':\n",
    "                cabin_list[i] = 1\n",
    "            elif temp_data[i]=='B':\n",
    "                cabin_list[i] = 2\n",
    "            elif temp_data[i]=='C':\n",
    "                cabin_list[i] = 3\n",
    "            elif temp_data[i]=='D':\n",
    "                cabin_list[i] = 4\n",
    "            elif temp_data[i]=='E':\n",
    "                cabin_list[i] = 5\n",
    "            elif temp_data[i]=='F':\n",
    "                cabin_list[i] = 6\n",
    "            elif temp_data[i]=='G':\n",
    "                cabin_list[i] = 7\n",
    "            elif temp_data[i]=='T':\n",
    "                cabin_list[i] = 8\n",
    "            else:\n",
    "                cabin_list[i] = 0\n",
    "        \n",
    "        data = self.normalize_data(cabin_list, data)\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    def make_analysis_data(self, csv_data):\n",
    "        \n",
    "        data = np.array([0, 0], dtype=np.float32);\n",
    "        \n",
    "        #### BLANK 처리를 추가해야한다 ####\n",
    "        #### 기본적으로는 -1이 괜찮나? 0과 구분이 되기만 하면 된다. ####\n",
    "        \n",
    "        data = self.normalize_data(csv_data['Pclass'], data)\n",
    "        data = self.normalize_char_data(csv_data['Sex'], data)\n",
    "        data = self.normalize_data(csv_data['Age'].fillna(-1), data)\n",
    "        data = self.normalize_data(csv_data['SibSp'], data)\n",
    "        data = self.normalize_data(csv_data['Parch'], data)\n",
    "        # TICKET\n",
    "        data = self.normalize_ticket_data(csv_data['Ticket'], data)\n",
    "        data = self.normalize_data(csv_data['Fare'], data)\n",
    "        # CABIN\n",
    "        data = self.normalize_cabin_data(csv_data['Cabin'].fillna(' '), data)\n",
    "        data = self.normalize_char_data(csv_data['Embarked'].fillna(-1), data)\n",
    "        \n",
    "        data = data.transpose()\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    def next_batch(self, x_data, y_data, batch_size):\n",
    "        # random int를 갯수만큼 수행하여 해당 index의 X와 Y를 리턴한다.\n",
    "        sample_indices = np.random.randint(0, len(y_data), size=batch_size)\n",
    "        return x_data[sample_indices, :], y_data[sample_indices, :]\n",
    "      \n",
    "        ############ Training Data ############\n",
    "        \n",
    "    def train_old(self, x_data, y_data, x_data_test, batch_size, traing_epoch):\n",
    "        \n",
    "        # construct network\n",
    "        X = tf.placeholder(tf.float32, [None, 10])\n",
    "        Y = tf.placeholder(tf.float32, [None, 1])\n",
    "        keep_prob = tf.placeholder(tf.float32)\n",
    "        \n",
    "        \n",
    "        num_of_weight = 100\n",
    "        with tf.variable_scope(\"L1\", reuse=tf.AUTO_REUSE):\n",
    "            W1 = tf.get_variable(\"W1\", shape=[10, num_of_weight], initializer=tf.contrib.layers.xavier_initializer())\n",
    "            b1 = tf.Variable(tf.random_normal([num_of_weight]), dtype=tf.float32, name = 'b1')\n",
    "            L1 = tf.nn.relu( tf.matmul(X, W1) + b1)\n",
    "            L1 = tf.nn.dropout(L1, keep_prob=keep_prob)\n",
    "        \n",
    "        with tf.variable_scope(\"L2\", reuse=tf.AUTO_REUSE):\n",
    "            W2 = tf.get_variable(\"W2\", shape=[num_of_weight, num_of_weight], initializer=tf.contrib.layers.xavier_initializer())\n",
    "            b2 = tf.Variable(tf.random_normal([num_of_weight]), dtype=tf.float32, name='b2')\n",
    "            L2 = tf.nn.relu( tf.matmul(L1, W2) + b2)\n",
    "            L2 = tf.nn.dropout(L2, keep_prob=keep_prob)\n",
    "\n",
    "        with tf.variable_scope(\"L3\", reuse=tf.AUTO_REUSE):\n",
    "            W3 = tf.get_variable(\"W3\", shape=[num_of_weight, num_of_weight], initializer=tf.contrib.layers.xavier_initializer())\n",
    "            b3 = tf.Variable(tf.random_normal([num_of_weight]), dtype=tf.float32, name='b3')\n",
    "            L3 = tf.nn.relu( tf.matmul(L2, W3) + b3)\n",
    "            L3 = tf.nn.dropout(L3, keep_prob=keep_prob)\n",
    "        \n",
    "        with tf.variable_scope(\"L4\", reuse=tf.AUTO_REUSE):\n",
    "            W4 = tf.get_variable(\"W4\", shape=[num_of_weight, num_of_weight], initializer=tf.contrib.layers.xavier_initializer())\n",
    "            b4 = tf.Variable(tf.random_normal([num_of_weight]), dtype=tf.float32, name='b4')\n",
    "            L4 = tf.nn.relu( tf.matmul(L3, W4) + b4)\n",
    "            L4 = tf.nn.dropout(L4, keep_prob=keep_prob)        \n",
    "        \n",
    "        with tf.variable_scope(\"LF\", reuse=tf.AUTO_REUSE):\n",
    "            WF = tf.get_variable(\"WF\", shape=[num_of_weight, 1], initializer=tf.contrib.layers.xavier_initializer())\n",
    "            bF = tf.Variable(tf.random_normal([1]), dtype=tf.float32, name='bF')\n",
    "        \n",
    "        with tf.variable_scope(\"Cal\", reuse=tf.AUTO_REUSE):    \n",
    "            hypothesis = tf.sigmoid( tf.matmul(L4, WF) + bF)\n",
    "            # cost/loss function\n",
    "            cost = - tf.reduce_mean(Y*tf.log(hypothesis)+(1-Y)*tf.log(1-hypothesis))\n",
    "        \n",
    "       # 이후는 동일\n",
    "        \n",
    "        \n",
    "    def train(self, x_data, y_data, x_data_test, batch_size, traing_epoch):\n",
    "        \n",
    "        # construct network\n",
    "        X = tf.placeholder(tf.float32, [None, 10])\n",
    "        Y = tf.placeholder(tf.float32, [None, 1])\n",
    "        keep_prob = tf.placeholder(tf.float32)\n",
    "        \n",
    "        num_of_node = 100\n",
    "        iscale = 0.01\n",
    "        \n",
    "        with tf.variable_scope('EasyNet', reuse=tf.AUTO_REUSE):\n",
    "          L1 = tf.contrib.layers.fully_connected(X, num_of_node, weights_regularizer=tf.contrib.layers.l2_regularizer(scale=iscale))\n",
    "          L1 = tf.nn.dropout(L1, keep_prob=keep_prob)\n",
    "\n",
    "          L2 = tf.contrib.layers.fully_connected(L1, num_of_node, weights_regularizer=tf.contrib.layers.l2_regularizer(scale=iscale))\n",
    "          L2 = tf.nn.dropout(L2, keep_prob=keep_prob)\n",
    "\n",
    "          L3 = tf.contrib.layers.fully_connected(L2, num_of_node, weights_regularizer=tf.contrib.layers.l2_regularizer(scale=iscale))\n",
    "          L3 = tf.nn.dropout(L3, keep_prob=keep_prob)\n",
    "\n",
    "          L4 = tf.contrib.layers.fully_connected(L3, 1, weights_regularizer=tf.contrib.layers.l2_regularizer(scale=iscale))\n",
    "        \n",
    "        with tf.variable_scope('Training', reuse=tf.AUTO_REUSE):\n",
    "          logit = tf.layers.dense(L4, 1)\n",
    "          hypothesis = tf.nn.sigmoid(logit)\n",
    "          \n",
    "          reg_ws = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES, 'EasyNet')\n",
    "          cost = tf.losses.sigmoid_cross_entropy(Y, logit) + tf.reduce_sum(reg_ws)\n",
    "        \n",
    "          # define gradient\n",
    "          gradient = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(cost)\n",
    "\n",
    "        # Accuracy Computation\n",
    "        predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "        accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32 ))\n",
    "\n",
    "        # init network\n",
    "        sess = tf.Session()\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        start_time = time.time()\n",
    "        for epoch in range(traing_epoch):\n",
    "            avg_cost = 0.0\n",
    "            total_batch = int(len(y_data)/batch_size)\n",
    "            for batch in range(total_batch):\n",
    "                batch_X, batch_Y = self.next_batch(x_data, y_data, batch_size)\n",
    "                cost_, _ = sess.run([cost, gradient], feed_dict={X: batch_X, Y:batch_Y, keep_prob:0.7})\n",
    "                avg_cost += cost_/total_batch\n",
    "            \n",
    "            if epoch%100 == 0:\n",
    "                print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "        \n",
    "        end_time = time.time()\n",
    "        print('Learning Time = ', end_time-start_time)\n",
    "        \n",
    "        # write result\n",
    "        print( sess.run([accuracy], feed_dict={X: x_data, Y: y_data, keep_prob:1.0}) )\n",
    "        \n",
    "        predict = sess.run(hypothesis, feed_dict={X: x_data_test, keep_prob:1.0})\n",
    "        # np.savetxt(\"./predict.csv\", predict, delimiter=\",\")\n",
    "        \n",
    "        \n",
    "        sess.close()\n",
    "        \n",
    "        return predict\n",
    "    \n",
    "    ############ Ensemble ############\n",
    "    \n",
    "    def get_result_ensemble(self, en_data):\n",
    "        avr_data = np.average(en_data, axis=1)\n",
    "        print(avr_data.shape)\n",
    "        \n",
    "        # Accuracy Computation\n",
    "        # predicted = np.cast(avr_data > 0.5, dtype=tf.int32)\n",
    "        predict = np.int32((avr_data > 0.5))\n",
    "        print(predict)\n",
    "        \n",
    "        np.savetxt(\"./predict.csv\", predict, delimiter=\",\")\n",
    "        # accuracy = np.reduce_mean(np.cast(np.equal(predicted, Y), dtype=np.float32 ))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute Code - Load_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created Titanic Object!\n",
      "train_dataX.shape =  (891, 10)\n",
      "train_dataX.shape =  (418, 10)\n"
     ]
    }
   ],
   "source": [
    "# 3. Loading Data & Analyze Data    \n",
    "titanic = TITANIC()\n",
    "train_dataX = titanic.make_analysis_data(train_x)\n",
    "print(\"train_dataX.shape = \", train_dataX.shape)\n",
    "\n",
    "test_dataX  = titanic.make_analysis_data(test_x)\n",
    "print(\"train_dataX.shape = \", test_dataX.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute Code - Train_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 1.785382837\n",
      "Epoch: 0101 cost = 1.201984555\n",
      "Learning Time =  2.2961087226867676\n",
      "[0.7979798]\n",
      "Epoch: 0001 cost = 1.800774872\n",
      "Epoch: 0101 cost = 1.234439552\n",
      "Learning Time =  2.092566728591919\n",
      "[0.7631874]\n",
      "Epoch: 0001 cost = 1.797257304\n",
      "Epoch: 0101 cost = 1.223364294\n",
      "Learning Time =  2.0734970569610596\n",
      "[0.7856341]\n",
      "Epoch: 0001 cost = 1.781733662\n",
      "Epoch: 0101 cost = 1.211535096\n",
      "Learning Time =  2.0714848041534424\n",
      "[0.78338945]\n",
      "Epoch: 0001 cost = 1.801866591\n",
      "Epoch: 0101 cost = 1.201474845\n",
      "Learning Time =  2.1506941318511963\n",
      "[0.7957351]\n",
      "Epoch: 0001 cost = 1.789952576\n",
      "Epoch: 0101 cost = 1.186721474\n",
      "Learning Time =  2.24898362159729\n",
      "[0.8069585]\n",
      "Epoch: 0001 cost = 1.796429366\n",
      "Epoch: 0101 cost = 1.113067210\n",
      "Learning Time =  2.0935678482055664\n",
      "[0.8148148]\n",
      "Epoch: 0001 cost = 1.777995437\n",
      "Epoch: 0101 cost = 1.177862912\n",
      "Learning Time =  2.2128870487213135\n",
      "[0.81257015]\n",
      "Epoch: 0001 cost = 1.791907430\n",
      "Epoch: 0101 cost = 1.190076053\n",
      "Learning Time =  2.077526807785034\n",
      "[0.8148148]\n",
      "Epoch: 0001 cost = 1.793811709\n",
      "Epoch: 0101 cost = 1.179955304\n",
      "Learning Time =  2.0825400352478027\n",
      "[0.81593716]\n",
      "(418,)\n",
      "[0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 1 0 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 1 1 0 0 1\n",
      " 1 0 0 0 0 0 1 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 1 1 0 0 0\n",
      " 1 0 0 1 0 1 0 0 0 0 0 0 1 1 1 0 1 0 1 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 1 1 1 1 0 0 1 0 1 1 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 1 0 0 1 0 1 0 0 0 0 1 0 0 1 0 1 0 1 0\n",
      " 1 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 1 0 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 1 0 0 0 1 0 1 0 0 0 0 1 1 0 1 1 0 0 1 0\n",
      " 0 1 0 0 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0\n",
      " 0 1 1 1 1 1 0 1 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramFiles\\Anaconda3\\envs\\tc\\lib\\site-packages\\ipykernel_launcher.py:291: RuntimeWarning: invalid value encountered in greater\n"
     ]
    }
   ],
   "source": [
    "# 4. Execute Ensemble Data\n",
    "ensembleSize = 10\n",
    "train_dataY = train_y.values.reshape(-1,1)\n",
    "\n",
    "for i in range(ensembleSize):\n",
    "    train_result = titanic.train(train_dataX, train_dataY, test_dataX, 200, 200)\n",
    "    \n",
    "    if i==0:\n",
    "        train_result_en = train_result\n",
    "    else:\n",
    "        train_result_en = np.hstack( (train_result_en, train_result) )\n",
    "        \n",
    "        \n",
    "# print(train_result_en)\n",
    "titanic.get_result_ensemble(train_result_en)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaggle Score"
   ]
  },
  {
   "attachments": {
    "Kaggle_Score.PNG": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Kaggle_Score.PNG](attachment:Kaggle_Score.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tc",
   "language": "python",
   "name": "tc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
