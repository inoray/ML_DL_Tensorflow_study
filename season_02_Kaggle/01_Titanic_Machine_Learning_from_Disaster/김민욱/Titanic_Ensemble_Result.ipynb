{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble을 이용한 타이타닉 생존자 예측 결과"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* pasdas를 사용하여 csv 파일을 컨트롤 해본다.\n",
    "* ensemble을 구현해본다.\n",
    "* 타이타닉 문제를 풀어본다.\n",
    "* 기타  프로젝트 중 직면한 문제를 해결해본다.\n",
    "    - 학습 중, Error Rate가 Nan이 되는 문제 해결\n",
    "* 그래프를 그려본다......가 추가되었다.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 코드 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* pasdas를 import 하였습니다.\n",
    "* anaconda에 pandas를 추가하는 과정을 수행했습니다....--;;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"./data/train.csv\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    0\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = train['Survived']\n",
    "train_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                               Name  \\\n",
       "0            1       3                            Braund, Mr. Owen Harris   \n",
       "1            2       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2            3       3                             Heikkinen, Miss. Laina   \n",
       "3            4       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4            5       3                           Allen, Mr. William Henry   \n",
       "\n",
       "      Sex   Age  SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "0    male  22.0      1      0         A/5 21171   7.2500   NaN        S  \n",
       "1  female  38.0      1      0          PC 17599  71.2833   C85        C  \n",
       "2  female  26.0      0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3  female  35.0      1      0            113803  53.1000  C123        S  \n",
       "4    male  35.0      0      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = train.drop(labels='Survived', axis=1)\n",
    "train_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x  = pd.read_csv(\"./data/test.csv\")\n",
    "test_x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TINANIC Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TITANIC:\n",
    "        \n",
    "    def __init__(self):\n",
    "        print(\"Created Titanic Object!\")\n",
    "    \n",
    "    ############ Loading Data ############\n",
    "    \n",
    "    def load_train_data(self, cvs_file_path):\n",
    "        \n",
    "        ## pandas csv load\n",
    "        self.train_data = pd.read_csv(cvs_file_path)\n",
    "                \n",
    "        self.train_y_data = self.train_data['Survived']\n",
    "        self.train_y = self.train_y_data.reshape(-1,1)\n",
    "        \n",
    "        # Logistic Regression 이므로 onehot은 필요없다.\n",
    "        # self.train_y_onehot = pd.get_dummies(self.train_y)\n",
    "        \n",
    "        self.train_x = self.train_data.drop(labels='Survived', axis=1)\n",
    "        \n",
    "    def load_test_data(self, cvs_file_path):\n",
    "        \n",
    "        ## pandas cvs load\n",
    "        self.test_data  = pd.read_csv(cvs_file_path)\n",
    "    \n",
    "    ############ Normalize Data ############\n",
    "    \n",
    "    # list의 최대값, 최소값을 받아서 0~1 사이의 값으로 바꾼다.\n",
    "    def normalize_data(self, data_list, data):\n",
    "        \n",
    "        '''\n",
    "        # 정규분포로 바꾼다.\n",
    "        data_avr = np.mean(data_list)\n",
    "        data_std = np.std(data_list)\n",
    "        \n",
    "        data_normal = (data_list-data_avr)/data_std\n",
    "        '''\n",
    "        \n",
    "        data_normal = data_list\n",
    "        max_value = np.max(data_normal)\n",
    "        min_value = np.min(data_normal)\n",
    "        data_normal = (data_normal-min_value)/(max_value-min_value)\n",
    "        \n",
    "        if data.size == 2:\n",
    "            data = data_normal\n",
    "        else:\n",
    "            data = np.vstack( (data, data_normal) )\n",
    "            \n",
    "        return data\n",
    "    \n",
    "    ## 데이터가 영문 단어일 경우 처리!\n",
    "    def normalize_char_data(self, data_list, data):\n",
    "        \n",
    "        # print(data_list.size)\n",
    "        temp_data = np.zeros([data_list.size], dtype=np.float32)\n",
    "        # print(temp_data.shape)\n",
    "        for i in range(data_list.size):\n",
    "            # SEX\n",
    "            if data_list[i]=='male':\n",
    "                temp_data[i] = 0\n",
    "            elif data_list[i]=='female':\n",
    "                temp_data[i] = 1\n",
    "            # Embarked\n",
    "            elif data_list[i]=='S':\n",
    "                temp_data[i] = 0\n",
    "            elif data_list[i]=='C':\n",
    "                temp_data[i] = 1\n",
    "            elif data_list[i]=='Q':\n",
    "                temp_data[i] = 2\n",
    "            # ETC\n",
    "            else:\n",
    "                temp_data[i] = 0\n",
    "        \n",
    "        data = self.normalize_data(temp_data, data)\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    def normalize_ticket_data(self, data_list, data):\n",
    "        \n",
    "        temp_data = []\n",
    "        \n",
    "        # 일단 ticket data에서 맨 뒷자리 공백까지의 숫자를 가져온다.\n",
    "        for i in range(data_list.size):\n",
    "            first_index = data_list[i].rfind(\" \")+1\n",
    "            temp_data.append(data_list[i][first_index:])\n",
    "        \n",
    "        # \"LINE\" 처리\n",
    "        length_list = np.zeros([len(temp_data)], dtype=np.int32)\n",
    "        for i in range(len(temp_data)):\n",
    "            if temp_data[i] == \"LINE\":\n",
    "                temp_data[i] = \"00\"\n",
    "        \n",
    "        # 티켓 번호의 자리수 분석\n",
    "        length_list = np.zeros([len(temp_data)], dtype=np.int32)\n",
    "        for i in range(len(temp_data)):\n",
    "            length_list[i] = len(temp_data[i])\n",
    "        \n",
    "        data = self.normalize_data(length_list, data)\n",
    "        \n",
    "        # 티켓 번호의 맨 앞자리수 분석\n",
    "        first_char_list = np.zeros([len(temp_data)], dtype=np.int32)\n",
    "        for i in range(len(temp_data)):\n",
    "            first_char_list[i] = (int)(temp_data[i][0])\n",
    "        \n",
    "        data = self.normalize_data(length_list, data)\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    def normalize_cabin_data(self, data_list, data):\n",
    "        \n",
    "        temp_data = []\n",
    "        # cabin의 앞자리 문자를 가져온다.\n",
    "        for i in range(data_list.size):\n",
    "            temp_data.append(data_list[i][0])\n",
    "        \n",
    "        cabin_list = np.zeros([len(temp_data)], dtype=np.int32)\n",
    "        for i in range(len(temp_data)):\n",
    "            \n",
    "            if temp_data[i]=='A':\n",
    "                cabin_list[i] = 1\n",
    "            elif temp_data[i]=='B':\n",
    "                cabin_list[i] = 2\n",
    "            elif temp_data[i]=='C':\n",
    "                cabin_list[i] = 3\n",
    "            elif temp_data[i]=='D':\n",
    "                cabin_list[i] = 4\n",
    "            elif temp_data[i]=='E':\n",
    "                cabin_list[i] = 5\n",
    "            elif temp_data[i]=='F':\n",
    "                cabin_list[i] = 6\n",
    "            elif temp_data[i]=='G':\n",
    "                cabin_list[i] = 7\n",
    "            elif temp_data[i]=='T':\n",
    "                cabin_list[i] = 8\n",
    "            else:\n",
    "                cabin_list[i] = 0\n",
    "        \n",
    "        data = self.normalize_data(cabin_list, data)\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    def make_analysis_data(self, csv_data):\n",
    "        \n",
    "        data = np.array([0, 0], dtype=np.float32);\n",
    "        \n",
    "        #### BLANK 처리를 추가해야한다 ####\n",
    "        #### 기본적으로는 -1이 괜찮나? 0과 구분이 되기만 하면 된다. ####\n",
    "        \n",
    "        data = self.normalize_data(csv_data['Pclass'], data)\n",
    "        data = self.normalize_char_data(csv_data['Sex'], data)\n",
    "        data = self.normalize_data(csv_data['Age'].fillna(-1), data)\n",
    "        data = self.normalize_data(csv_data['SibSp'], data)\n",
    "        data = self.normalize_data(csv_data['Parch'], data)\n",
    "        # TICKET\n",
    "        data = self.normalize_ticket_data(csv_data['Ticket'], data)\n",
    "        data = self.normalize_data(csv_data['Fare'], data)\n",
    "        # CABIN\n",
    "        data = self.normalize_cabin_data(csv_data['Cabin'].fillna(' '), data)\n",
    "        data = self.normalize_char_data(csv_data['Embarked'].fillna(-1), data)\n",
    "        \n",
    "        data = data.transpose()\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    def next_batch(self, x_data, y_data, batch_size):\n",
    "        # random int를 갯수만큼 수행하여 해당 index의 X와 Y를 리턴한다.\n",
    "        sample_indices = np.random.randint(0, len(y_data), size=batch_size)\n",
    "        return x_data[sample_indices, :], y_data[sample_indices, :]\n",
    "      \n",
    "        ############ Training Data ############\n",
    "        \n",
    "    def train_old(self, x_data, y_data, x_data_test, batch_size, traing_epoch):\n",
    "        \n",
    "        # construct network\n",
    "        X = tf.placeholder(tf.float32, [None, 10])\n",
    "        Y = tf.placeholder(tf.float32, [None, 1])\n",
    "        keep_prob = tf.placeholder(tf.float32)\n",
    "        \n",
    "        \n",
    "        num_of_weight = 100\n",
    "        with tf.variable_scope(\"L1\", reuse=tf.AUTO_REUSE):\n",
    "            W1 = tf.get_variable(\"W1\", shape=[10, num_of_weight], initializer=tf.contrib.layers.xavier_initializer())\n",
    "            b1 = tf.Variable(tf.random_normal([num_of_weight]), dtype=tf.float32, name = 'b1')\n",
    "            L1 = tf.nn.relu( tf.matmul(X, W1) + b1)\n",
    "            L1 = tf.nn.dropout(L1, keep_prob=keep_prob)\n",
    "        \n",
    "        with tf.variable_scope(\"L2\", reuse=tf.AUTO_REUSE):\n",
    "            W2 = tf.get_variable(\"W2\", shape=[num_of_weight, num_of_weight], initializer=tf.contrib.layers.xavier_initializer())\n",
    "            b2 = tf.Variable(tf.random_normal([num_of_weight]), dtype=tf.float32, name='b2')\n",
    "            L2 = tf.nn.relu( tf.matmul(L1, W2) + b2)\n",
    "            L2 = tf.nn.dropout(L2, keep_prob=keep_prob)\n",
    "\n",
    "        with tf.variable_scope(\"L3\", reuse=tf.AUTO_REUSE):\n",
    "            W3 = tf.get_variable(\"W3\", shape=[num_of_weight, num_of_weight], initializer=tf.contrib.layers.xavier_initializer())\n",
    "            b3 = tf.Variable(tf.random_normal([num_of_weight]), dtype=tf.float32, name='b3')\n",
    "            L3 = tf.nn.relu( tf.matmul(L2, W3) + b3)\n",
    "            L3 = tf.nn.dropout(L3, keep_prob=keep_prob)\n",
    "        \n",
    "        with tf.variable_scope(\"L4\", reuse=tf.AUTO_REUSE):\n",
    "            W4 = tf.get_variable(\"W4\", shape=[num_of_weight, num_of_weight], initializer=tf.contrib.layers.xavier_initializer())\n",
    "            b4 = tf.Variable(tf.random_normal([num_of_weight]), dtype=tf.float32, name='b4')\n",
    "            L4 = tf.nn.relu( tf.matmul(L3, W4) + b4)\n",
    "            L4 = tf.nn.dropout(L4, keep_prob=keep_prob)        \n",
    "        \n",
    "        with tf.variable_scope(\"LF\", reuse=tf.AUTO_REUSE):\n",
    "            WF = tf.get_variable(\"WF\", shape=[num_of_weight, 1], initializer=tf.contrib.layers.xavier_initializer())\n",
    "            bF = tf.Variable(tf.random_normal([1]), dtype=tf.float32, name='bF')\n",
    "        \n",
    "        with tf.variable_scope(\"Cal\", reuse=tf.AUTO_REUSE):    \n",
    "            hypothesis = tf.sigmoid( tf.matmul(L4, WF) + bF)\n",
    "            # cost/loss function\n",
    "            cost = - tf.reduce_mean(Y*tf.log(hypothesis)+(1-Y)*tf.log(1-hypothesis))\n",
    "        \n",
    "       # 이후는 동일\n",
    "        \n",
    "        \n",
    "    def train(self, x_data, y_data, x_data_test, batch_size, traing_epoch):\n",
    "        \n",
    "        # construct network\n",
    "        X = tf.placeholder(tf.float32, [None, 10])\n",
    "        Y = tf.placeholder(tf.float32, [None, 1])\n",
    "        keep_prob = tf.placeholder(tf.float32)\n",
    "        \n",
    "        num_of_node = 100\n",
    "        iscale = 0.01\n",
    "        \n",
    "        with tf.variable_scope('EasyNet', reuse=tf.AUTO_REUSE):\n",
    "          L1 = tf.contrib.layers.fully_connected(X, num_of_node, weights_regularizer=tf.contrib.layers.l2_regularizer(scale=iscale))\n",
    "          L1 = tf.nn.dropout(L1, keep_prob=keep_prob)\n",
    "\n",
    "          L2 = tf.contrib.layers.fully_connected(L1, num_of_node, weights_regularizer=tf.contrib.layers.l2_regularizer(scale=iscale))\n",
    "          L2 = tf.nn.dropout(L2, keep_prob=keep_prob)\n",
    "\n",
    "          L3 = tf.contrib.layers.fully_connected(L2, num_of_node, weights_regularizer=tf.contrib.layers.l2_regularizer(scale=iscale))\n",
    "          L3 = tf.nn.dropout(L3, keep_prob=keep_prob)\n",
    "\n",
    "          L4 = tf.contrib.layers.fully_connected(L3, 1, weights_regularizer=tf.contrib.layers.l2_regularizer(scale=iscale))\n",
    "        \n",
    "        with tf.variable_scope('Training', reuse=tf.AUTO_REUSE):\n",
    "          logit = tf.layers.dense(L4, 1)\n",
    "          hypothesis = tf.nn.sigmoid(logit)\n",
    "          \n",
    "          reg_ws = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES, 'EasyNet')\n",
    "          cost = tf.losses.sigmoid_cross_entropy(Y, logit) + tf.reduce_sum(reg_ws)\n",
    "        \n",
    "          # define gradient\n",
    "          gradient = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(cost)\n",
    "\n",
    "        # Accuracy Computation\n",
    "        predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "        accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32 ))\n",
    "\n",
    "        # init network\n",
    "        sess = tf.Session()\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        start_time = time.time()\n",
    "        for epoch in range(traing_epoch):\n",
    "            avg_cost = 0.0\n",
    "            total_batch = int(len(y_data)/batch_size)\n",
    "            for batch in range(total_batch):\n",
    "                batch_X, batch_Y = self.next_batch(x_data, y_data, batch_size)\n",
    "                cost_, _ = sess.run([cost, gradient], feed_dict={X: batch_X, Y:batch_Y, keep_prob:0.7})\n",
    "                avg_cost += cost_/total_batch\n",
    "            \n",
    "            if epoch%100 == 0:\n",
    "                print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "        \n",
    "        end_time = time.time()\n",
    "        print('Learning Time = ', end_time-start_time)\n",
    "        \n",
    "        # write result\n",
    "        print( sess.run([accuracy], feed_dict={X: x_data, Y: y_data, keep_prob:1.0}) )\n",
    "        \n",
    "        predict = sess.run(hypothesis, feed_dict={X: x_data_test, keep_prob:1.0})\n",
    "        # np.savetxt(\"./predict.csv\", predict, delimiter=\",\")\n",
    "        \n",
    "        \n",
    "        sess.close()\n",
    "        \n",
    "        return predict\n",
    "    \n",
    "    ############ Ensemble ############\n",
    "    \n",
    "    def get_result_ensemble(self, en_data):\n",
    "        avr_data = np.average(en_data, axis=1)\n",
    "        print(avr_data.shape)\n",
    "        \n",
    "        # Accuracy Computation\n",
    "        # predicted = np.cast(avr_data > 0.5, dtype=tf.int32)\n",
    "        predict = np.int32((avr_data > 0.5))\n",
    "        print(predict)\n",
    "        \n",
    "        np.savetxt(\"./predict.csv\", predict, delimiter=\",\")\n",
    "        # accuracy = np.reduce_mean(np.cast(np.equal(predicted, Y), dtype=np.float32 ))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute Code - Load_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created Titanic Object!\n",
      "train_dataX.shape =  (891, 10)\n",
      "train_dataX.shape =  (418, 10)\n"
     ]
    }
   ],
   "source": [
    "# 3. Loading Data & Analyze Data    \n",
    "titanic = TITANIC()\n",
    "train_dataX = titanic.make_analysis_data(train_x)\n",
    "print(\"train_dataX.shape = \", train_dataX.shape)\n",
    "\n",
    "test_dataX  = titanic.make_analysis_data(test_x)\n",
    "print(\"train_dataX.shape = \", test_dataX.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute Code - Train_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 1.785382837\n",
      "Epoch: 0101 cost = 1.201984555\n",
      "Learning Time =  2.2961087226867676\n",
      "[0.7979798]\n",
      "Epoch: 0001 cost = 1.800774872\n",
      "Epoch: 0101 cost = 1.234439552\n",
      "Learning Time =  2.092566728591919\n",
      "[0.7631874]\n",
      "Epoch: 0001 cost = 1.797257304\n",
      "Epoch: 0101 cost = 1.223364294\n",
      "Learning Time =  2.0734970569610596\n",
      "[0.7856341]\n",
      "Epoch: 0001 cost = 1.781733662\n",
      "Epoch: 0101 cost = 1.211535096\n",
      "Learning Time =  2.0714848041534424\n",
      "[0.78338945]\n",
      "Epoch: 0001 cost = 1.801866591\n",
      "Epoch: 0101 cost = 1.201474845\n",
      "Learning Time =  2.1506941318511963\n",
      "[0.7957351]\n",
      "Epoch: 0001 cost = 1.789952576\n",
      "Epoch: 0101 cost = 1.186721474\n",
      "Learning Time =  2.24898362159729\n",
      "[0.8069585]\n",
      "Epoch: 0001 cost = 1.796429366\n",
      "Epoch: 0101 cost = 1.113067210\n",
      "Learning Time =  2.0935678482055664\n",
      "[0.8148148]\n",
      "Epoch: 0001 cost = 1.777995437\n",
      "Epoch: 0101 cost = 1.177862912\n",
      "Learning Time =  2.2128870487213135\n",
      "[0.81257015]\n",
      "Epoch: 0001 cost = 1.791907430\n",
      "Epoch: 0101 cost = 1.190076053\n",
      "Learning Time =  2.077526807785034\n",
      "[0.8148148]\n",
      "Epoch: 0001 cost = 1.793811709\n",
      "Epoch: 0101 cost = 1.179955304\n",
      "Learning Time =  2.0825400352478027\n",
      "[0.81593716]\n",
      "(418,)\n",
      "[0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 1 0 0 0 1 0 0 1 0 1 0 1 0 0 0 0 0 1 1 0 0 1\n",
      " 1 0 0 0 0 0 1 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 1 1 0 0 0\n",
      " 1 0 0 1 0 1 0 0 0 0 0 0 1 1 1 0 1 0 1 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 1 1 1 1 0 0 1 0 1 1 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 1 1 0 0 1 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 1 0 0 1 0 1 0 0 0 0 1 0 0 1 0 1 0 1 0\n",
      " 1 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 1 0 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 1 0 0 0 1 0 1 0 0 0 0 1 1 0 1 1 0 0 1 0\n",
      " 0 1 0 0 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0\n",
      " 0 1 1 1 1 1 0 1 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramFiles\\Anaconda3\\envs\\tc\\lib\\site-packages\\ipykernel_launcher.py:291: RuntimeWarning: invalid value encountered in greater\n"
     ]
    }
   ],
   "source": [
    "# 4. Execute Ensemble Data\n",
    "ensembleSize = 10\n",
    "train_dataY = train_y.values.reshape(-1,1)\n",
    "\n",
    "for i in range(ensembleSize):\n",
    "    train_result = titanic.train(train_dataX, train_dataY, test_dataX, 200, 200)\n",
    "    \n",
    "    if i==0:\n",
    "        train_result_en = train_result\n",
    "    else:\n",
    "        train_result_en = np.hstack( (train_result_en, train_result) )\n",
    "        \n",
    "        \n",
    "# print(train_result_en)\n",
    "titanic.get_result_ensemble(train_result_en)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaggle Score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tensorboard](./Kaggle_Score.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
