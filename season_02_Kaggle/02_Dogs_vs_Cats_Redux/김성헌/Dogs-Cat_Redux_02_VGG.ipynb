{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dogs vs. Cats Redux: Kernels Edition\n",
    "\n",
    "## 2. 모델구성 및 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shkim/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from IPython.display import display, Image, HTML\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Model class\n",
    "VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_Vgg19:\n",
    "\n",
    "    def __init__(self, sess, name):\n",
    "        self.sess = sess\n",
    "        self.name = name\n",
    "\n",
    "    def build_net(self, image_size):\n",
    "        with tf.variable_scope(self.name):\n",
    "            # dropout (keep_prob) rate  0.7~0.5 on training, but should be 1\n",
    "            # for testing\n",
    "            self.training = tf.placeholder(tf.bool)\n",
    "\n",
    "            # input place holders\n",
    "            self.X = tf.placeholder(tf.float32, [None, image_size, image_size, 3])\n",
    "            self.Y = tf.placeholder(tf.float32, [None, 2])\n",
    "            self.learning_rate = tf.placeholder(tf.float32)\n",
    "\n",
    "            # Convolutional Layer #1\n",
    "            conv1_1 = tf.layers.conv2d(inputs=self.X, filters=64, kernel_size=[3, 3], padding=\"SAME\", activation=tf.nn.relu)\n",
    "            conv1_2 = tf.layers.conv2d(inputs=conv1_1, filters=64, kernel_size=[3, 3], padding=\"SAME\", activation=tf.nn.relu)\n",
    "            pool1 = tf.layers.max_pooling2d(inputs=conv1_2, pool_size=[2, 2], padding=\"SAME\", strides=2)\n",
    "            \n",
    "            conv2_1 = tf.layers.conv2d(inputs=pool1, filters=128, kernel_size=[3, 3], padding=\"SAME\", activation=tf.nn.relu)\n",
    "            conv2_2 = tf.layers.conv2d(inputs=conv2_1, filters=128, kernel_size=[3, 3], padding=\"SAME\", activation=tf.nn.relu)\n",
    "            pool2 = tf.layers.max_pooling2d(inputs=conv2_2, pool_size=[2, 2], padding=\"SAME\", strides=2)\n",
    "            \n",
    "            conv3_1 = tf.layers.conv2d(inputs=pool2, filters=256, kernel_size=[3, 3], padding=\"SAME\", activation=tf.nn.relu)\n",
    "            conv3_2 = tf.layers.conv2d(inputs=conv3_1, filters=256, kernel_size=[3, 3], padding=\"SAME\", activation=tf.nn.relu)\n",
    "            conv3_3 = tf.layers.conv2d(inputs=conv3_2, filters=256, kernel_size=[3, 3], padding=\"SAME\", activation=tf.nn.relu)\n",
    "            conv3_4 = tf.layers.conv2d(inputs=conv3_3, filters=256, kernel_size=[3, 3], padding=\"SAME\", activation=tf.nn.relu)\n",
    "            pool3 = tf.layers.max_pooling2d(inputs=conv3_4, pool_size=[2, 2], padding=\"SAME\", strides=2)\n",
    "            \n",
    "            #conv4_1 = tf.layers.conv2d(inputs=pool3, filters=512, kernel_size=[3, 3], padding=\"SAME\", activation=tf.nn.relu)\n",
    "            #conv4_2 = tf.layers.conv2d(inputs=conv4_1, filters=512, kernel_size=[3, 3], padding=\"SAME\", activation=tf.nn.relu)\n",
    "            #conv4_3 = tf.layers.conv2d(inputs=conv4_2, filters=512, kernel_size=[3, 3], padding=\"SAME\", activation=tf.nn.relu)\n",
    "            #conv4_4 = tf.layers.conv2d(inputs=conv4_3, filters=512, kernel_size=[3, 3], padding=\"SAME\", activation=tf.nn.relu)\n",
    "            #pool4 = tf.layers.max_pooling2d(inputs=conv4_3, pool_size=[2, 2], padding=\"SAME\", strides=2)\n",
    "            \n",
    "            #conv5_1 = tf.layers.conv2d(inputs=pool4, filters=512, kernel_size=[3, 3], padding=\"SAME\", activation=tf.nn.relu)\n",
    "            #conv5_2 = tf.layers.conv2d(inputs=conv5_1, filters=512, kernel_size=[3, 3], padding=\"SAME\", activation=tf.nn.relu)\n",
    "            #conv5_3 = tf.layers.conv2d(inputs=conv5_2, filters=512, kernel_size=[3, 3], padding=\"SAME\", activation=tf.nn.relu)\n",
    "            #conv5_4 = tf.layers.conv2d(inputs=conv5_3, filters=512, kernel_size=[3, 3], padding=\"SAME\", activation=tf.nn.relu)\n",
    "            #pool5 = tf.layers.max_pooling2d(inputs=conv5_3, pool_size=[2, 2], padding=\"SAME\", strides=2)\n",
    "            \n",
    "            initializer = tf.contrib.layers.xavier_initializer()\n",
    "            \n",
    "            # 150 -> 75 -> 38 -> 19 -> 10 -> 5\n",
    "            # Dense Layer with Relu\n",
    "            flat6 = tf.reshape(pool3, [-1, 256 * 19 * 19])\n",
    "            #fc6 = tf.layers.dense(inputs=flat6, units=6400, activation=tf.nn.relu, kernel_initializer=initializer)\n",
    "            fc6 = tf.layers.dense(inputs=flat6, units=1000, activation=tf.nn.relu, kernel_initializer=initializer)\n",
    "            dropout6 = tf.layers.dropout(inputs=fc6, rate=0.5, training=self.training)\n",
    "\n",
    "            flat7 = tf.reshape(dropout6, [-1, 1000])\n",
    "            #fc7 = tf.layers.dense(inputs=flat7, units=3200, activation=tf.nn.relu, kernel_initializer=initializer)\n",
    "            fc7 = tf.layers.dense(inputs=flat7, units=500, activation=tf.nn.relu, kernel_initializer=initializer)\n",
    "            dropout7 = tf.layers.dropout(inputs=fc7, rate=0.5, training=self.training)\n",
    "\n",
    "            # Logits (no activation) Layer: L7 Final FC 625 inputs -> 2 outputs\n",
    "            self.logits = tf.layers.dense(inputs=dropout7, units=2)\n",
    "            \n",
    "        # define cost/loss & optimizer\n",
    "        self.cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=self.logits, labels=self.Y))\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate=self.learning_rate).minimize(self.cost)\n",
    "\n",
    "        self.prediction = tf.argmax(tf.nn.softmax(self.logits), axis=1)\n",
    "        correct_prediction = tf.equal(self.prediction, tf.argmax(self.Y, axis=1))\n",
    "        self.correct_count = tf.reduce_sum(tf.cast(correct_prediction, tf.float32))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        \n",
    "        # tensorboard data\n",
    "        tf.summary.scalar(\"cost\", self.cost)\n",
    "        tf.summary.scalar(\"accuracy\", self.accuracy)\n",
    "        self.summary = tf.summary.merge_all()\n",
    "\n",
    "    def predict(self, x_test):\n",
    "        return self.sess.run(self.logits, feed_dict={self.X: x_test, self.training: False})\n",
    "\n",
    "    def countCorrect(self, x_test, y_test):\n",
    "        return self.sess.run(self.correct_count, feed_dict={self.X: x_test, self.Y: y_test, self.training: False})\n",
    "\n",
    "    def get_accuracy(self, x_test, y_test):\n",
    "        return self.sess.run(self.accuracy, feed_dict={self.X: x_test, self.Y: y_test, self.training: False})\n",
    "    \n",
    "    def get_cost(self, x_test, y_test):\n",
    "        return self.sess.run(self.cost, feed_dict={self.X: x_test, self.Y: y_test, self.training: False})\n",
    "\n",
    "    def summary(self, x_test, y_test):\n",
    "        return self.sess.run(self.summary, feed_dict={self.X: x_test, self.Y: y_test, self.training: False})\n",
    "    \n",
    "    def train(self, x_data, y_data, learning_rate, training=True):\n",
    "        return self.sess.run([self.summary, self.cost, self.optimizer], feed_dict={self.X: x_data, self.Y: y_data, self.learning_rate: learning_rate, self.training: training})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 이미지 파일 리스트 가져 오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dogs:  12500\n",
      "train_cats:  12500\n",
      "test_images:  12500\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = \"../data/\"\n",
    "TRAIN_DIR = DATA_DIR + \"train_resize/\"\n",
    "TEST_DIR = DATA_DIR + \"test_resize/\"\n",
    "\n",
    "train_images = [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR)] \n",
    "train_dogs =   [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR) if 'dog' in i]\n",
    "train_cats =   [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR) if 'cat' in i]\n",
    "test_images =  [TEST_DIR+i for i in os.listdir(TEST_DIR)]\n",
    "\n",
    "print(\"train_dogs: \", len(train_dogs))\n",
    "print(\"train_cats: \", len(train_cats))\n",
    "print(\"test_images: \", len(test_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 학습데이터와 valid 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  17500\n",
      "valid:  7500\n"
     ]
    }
   ],
   "source": [
    "#train_dogs = train_dogs[:100]\n",
    "#train_cats = train_cats[:100]\n",
    "\n",
    "train_dog_cat = train_dogs + train_cats\n",
    "\n",
    "label_dog = [0 for i in range(len(train_dogs))]\n",
    "label_cat = [1 for i in range(len(train_cats))]\n",
    "label = label_dog + label_cat\n",
    "label_one_hot = np.eye(2)[label]\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split (\n",
    "    train_dog_cat, label_one_hot, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"train: \", len(x_train))\n",
    "print(\"valid: \", len(x_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/shkim/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "model = Model_Vgg19(sess, \"model\")\n",
    "model.build_net(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "epochs = 20\n",
    "batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBatchRange (data_size, batch_size, iterater):\n",
    "    begin_idx = iterater * batch_size\n",
    "    end_idx = begin_idx + batch_size\n",
    "    end_idx = min(end_idx, data_size - 1)\n",
    "    return begin_idx, end_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImageData (image_file_list, image_width = 150, image_height = 150, channel = 3):\n",
    "    data = np.ndarray((len(image_file_list), image_width, image_height, channel), dtype=np.uint8)\n",
    "    for i, image_file in enumerate(image_file_list):\n",
    "        data[i] = cv2.imread(image_file)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBatchData (x_data, y_data, batch_size, iterater):\n",
    "    begin_idx, end_idx = getBatchRange(len(x_data), batch_size, i)\n",
    "    \n",
    "    batch_x = x_data[begin_idx : end_idx]\n",
    "    batch_y = y_data[begin_idx : end_idx]\n",
    "    batch_y = np.reshape(batch_y, [-1,2])\n",
    "    \n",
    "    # 리사이즈 이미지 로드\n",
    "    batch_x_image = getImageData(batch_x)\n",
    "    \n",
    "    return batch_x_image, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning started. It takes sometime.\n",
      "Epoch: 0001 train [cost:  0.707457069 , acc: 0.6352] valid [cost:  0.568128114 , acc: 0.7020]  526.11 seconds\n",
      "Save checkpoint  : ./model.ckpt\n",
      "Epoch: 0002 train [cost:  0.544926585 , acc: 0.7542] valid [cost:  0.465250077 , acc: 0.7787]  522.48 seconds\n",
      "Epoch: 0003 train [cost:  0.444990527 , acc: 0.8234] valid [cost:  0.382401820 , acc: 0.8269]  527.55 seconds\n",
      "Epoch: 0004 train [cost:  0.327506952 , acc: 0.8898] valid [cost:  0.387716878 , acc: 0.8256]  530.43 seconds\n",
      "Epoch: 0005 train [cost:  0.235721885 , acc: 0.9354] valid [cost:  0.401837160 , acc: 0.8369]  530.35 seconds\n",
      "Epoch: 0006 train [cost:  0.168372061 , acc: 0.9675] valid [cost:  0.400888330 , acc: 0.8592]  529.98 seconds\n",
      "Epoch: 0007 train [cost:  0.123762147 , acc: 0.9809] valid [cost:  0.334093438 , acc: 0.8884]  529.94 seconds\n",
      "Epoch: 0008 train [cost:  0.098763611 , acc: 0.9884] valid [cost:  0.373047715 , acc: 0.8868]  530.32 seconds\n",
      "Epoch: 0009 train [cost:  0.070632317 , acc: 0.9950] valid [cost:  0.638169493 , acc: 0.8585]  530.36 seconds\n",
      "Epoch: 0010 train [cost:  0.060615981 , acc: 0.9977] valid [cost:  0.417378263 , acc: 0.9004]  530.35 seconds\n",
      "Epoch: 0011 train [cost:  0.045755621 , acc: 0.9990] valid [cost:  0.569777891 , acc: 0.8861]  530.31 seconds\n",
      "Save checkpoint  : ./model.ckpt\n",
      "Epoch: 0012 train [cost:  0.044549536 , acc: 0.9987] valid [cost:  0.504595040 , acc: 0.8909]  530.47 seconds\n",
      "Epoch: 0013 train [cost:  0.039163010 , acc: 0.9990] valid [cost:  0.497126903 , acc: 0.8732]  530.40 seconds\n",
      "Epoch: 0014 train [cost:  0.032651703 , acc: 0.9994] valid [cost:  0.447625568 , acc: 0.8979]  530.53 seconds\n",
      "Epoch: 0015 train [cost:  0.033795467 , acc: 0.9993] valid [cost:  0.614203241 , acc: 0.8653]  530.34 seconds\n",
      "Epoch: 0016 train [cost:  0.034094125 , acc: 0.9993] valid [cost:  0.485190043 , acc: 0.8911]  530.40 seconds\n",
      "Epoch: 0017 train [cost:  0.021644241 , acc: 0.9996] valid [cost:  0.435349290 , acc: 0.8924]  530.44 seconds\n",
      "Epoch: 0018 train [cost:  0.029736339 , acc: 0.9992] valid [cost:  0.454069574 , acc: 0.8937]  530.54 seconds\n",
      "Epoch: 0019 train [cost:  0.022631326 , acc: 0.9997] valid [cost:  0.484475194 , acc: 0.8989]  530.40 seconds\n",
      "Epoch: 0020 train [cost:  0.020388274 , acc: 0.9995] valid [cost:  0.665008273 , acc: 0.8912]  530.24 seconds\n",
      "Save checkpoint  : ./model.ckpt\n",
      "Learning Finished!\n",
      "--- 10597.23 seconds ---\n"
     ]
    }
   ],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "start_time = time.time()\n",
    "train_count = len(x_train)\n",
    "total_batch_train = int(train_count / batch_size)\n",
    "valid_count = len(x_valid)\n",
    "total_batch_valid = int(valid_count/batch_size)\n",
    "\n",
    "# usage\n",
    "# tensorboard --logdir=./log\n",
    "train_writer = tf.summary.FileWriter(\"./log/train\")\n",
    "valid_writer = tf.summary.FileWriter(\"./log/valid\")\n",
    "train_writer.add_graph(sess.graph)\n",
    "train_global_step = 0\n",
    "valid_global_step = 0\n",
    "\n",
    "print('Learning started. It takes sometime.') \n",
    "for epoch in range(epochs):\n",
    "    avg_cost_train = 0\n",
    "    avg_cost_valid = 0\n",
    "    accuracy_train = 0\n",
    "    accuracy_valid = 0\n",
    "    \n",
    "    correct_count_train = 0\n",
    "    correct_count_valid = 0\n",
    "    \n",
    "    start_time_epoch = time.time()\n",
    "    for i in range(total_batch_train):\n",
    "        batch_x_image, batch_y = getBatchData(x_train, y_train, batch_size, i)\n",
    "       \n",
    "        s, c, _ = model.train(batch_x_image, batch_y, learning_rate)\n",
    "        avg_cost_train += c / total_batch_train\n",
    "        correct_count_train += model.countCorrect(batch_x_image, batch_y)\n",
    "        \n",
    "        train_writer.add_summary(s, global_step=train_global_step)\n",
    "        train_global_step += 1\n",
    "    \n",
    "    accuracy_train = correct_count_train / train_count\n",
    "    \n",
    "    for i in range(total_batch_valid):\n",
    "        batch_x_image, batch_y = getBatchData(x_valid, y_valid, batch_size, i)\n",
    "        c = model.get_cost(batch_x_image, batch_y)\n",
    "        avg_cost_valid += c / total_batch_valid\n",
    "        \n",
    "        correct_count_valid += model.countCorrect(batch_x_image, batch_y)\n",
    "        #s = model.summary(batch_x_image, batch_y)\n",
    "        #valid_writer.add_summary(s, global_step=valid_global_step)\n",
    "        #valid_global_step += 1\n",
    "        \n",
    "    accuracy_valid = correct_count_valid / valid_count\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1)\n",
    "          , 'train [cost: ', '{:.9f}'.format(avg_cost_train), ', acc: %.4f]' % accuracy_train\n",
    "          , 'valid [cost: ', '{:.9f}'.format(avg_cost_valid), ', acc: %.4f]' % accuracy_valid\n",
    "          , \" %.2f seconds\" % (time.time() - start_time_epoch))\n",
    "    \n",
    "    \n",
    "    if epoch % 10 == 0 or (epoch + 1) == epochs:\n",
    "        checkpoint_path = os.path.join('./', 'model.ckpt')\n",
    "        saver.save(sess, checkpoint_path, global_step=epoch)\n",
    "        print('Save checkpoint  : %s' %(checkpoint_path))\n",
    "\n",
    "print('Learning Finished!') \n",
    "print(\"--- %.2f seconds ---\" %(time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test-accuracy: 0.9922\n",
      "--- 120.07 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "total_batch = int(train_count / batch_size)\n",
    "correct_count = 0\n",
    "for i in range(total_batch):\n",
    "    batch_x_image, batch_y = getBatchData(x_train, y_train, batch_size, i)\n",
    "    correct_count += model.countCorrect(batch_x_image, batch_y)\n",
    "\n",
    "accuracy = correct_count / train_count\n",
    "print(\"test-accuracy: %.4f\" % accuracy)\n",
    "print(\"--- %.2f seconds ---\" %(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid-accuracy: 0.8912\n",
      "--- 51.27 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "valid_count = len(x_valid)\n",
    "total_batch = int(valid_count / batch_size)\n",
    "correct_count = 0\n",
    "for i in range(total_batch):\n",
    "    batch_x_image, batch_y = getBatchData(x_valid, y_valid, batch_size, i)\n",
    "    correct_count += model.countCorrect(batch_x_image, batch_y)\n",
    "\n",
    "accuracy = correct_count / valid_count\n",
    "print(\"valid-accuracy: %.4f\" % accuracy)\n",
    "print(\"--- %.2f seconds ---\" %(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
